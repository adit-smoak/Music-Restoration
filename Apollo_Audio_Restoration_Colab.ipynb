{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NuwnC--VPO4"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "#@markdown #Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/JusperLee/Apollo.git && cd Apollo\n",
        "\n",
        "!mkdir /content/Apollo/model\n",
        "%cd /content/Apollo/model\n",
        "!wget 'https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin'\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model.ckpt'\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt'\n",
        "!wget 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/apollo_model_uni.ckpt'\n",
        "\n",
        "%cd /content/Apollo/configs\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml'\n",
        "!wget 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml'\n",
        "\n",
        "!rm -rf '/content/Apollo/inference.py'\n",
        "%cd /content/Apollo\n",
        "!wget 'https://raw.githubusercontent.com/adit-smoak/Music-Restoration/refs/heads/main/inference.py'\n",
        "\n",
        "!pip install omegaconf ml_collections"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsNmuNpIvvzh",
        "outputId": "b40bc6e5-e540-4f8f-dd2e-e94bd40556dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFqIYcKxVXyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c6605d-5212-44cf-ff89-05f202027802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Apollo\n",
            "_target_: look2hear.models.apollo.Apollo\n",
            "feature_dim: 384\n",
            "layer: 6\n",
            "sr: 44100\n",
            "win: 20\n",
            "\n",
            "ckpt_path = /content/Apollo/model/apollo_model_uni.ckpt\n",
            "chunk_size = 19, overlap = 2\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, np.int64(47)] 80\n",
            "INPUT audio.shape = (2, 8404596) | samplerate = 44100\n",
            "N = 2 | C = 837900 | step = 418950 | fade_size = 132300\n",
            "Processing audio chunks:  18% 1675800/9242496 [00:40<03:04, 41007.29it/s]"
          ]
        }
      ],
      "source": [
        "%cd /content/Apollo\n",
        "#@markdown #Inference\n",
        "#@markdown For the universal model set *chunk_size* above to 19, for all other models set it to 25\n",
        "input_file_path = '/content/drive/inputpath' #@param {type:\"string\"}\n",
        "output_file_path = '/content/drive/MyDrive/outputpath' #@param {type:\"string\"}\n",
        "model = 'Lew Universal Lossy Enhancer' #@param ['MP3 Enhancer', 'Lew Vocal Enhancer', 'Lew Vocal Enhancer v2 (beta)', 'Lew Universal Lossy Enhancer']\n",
        "chunk_size = 19 #@param {type:\"slider\", min:3, max:25, step:1}\n",
        "overlap = 2 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "if model == 'MP3 Enhancer':\n",
        "    ckpt = '/content/Apollo/model/pytorch_model.bin'\n",
        "    config = 'configs/apollo.yaml'\n",
        "if model == 'Lew Vocal Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model.ckpt'\n",
        "    config = 'configs/apollo.yaml'\n",
        "if model == 'Lew Vocal Enhancer v2 (beta)':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_v2.ckpt'\n",
        "    config = 'configs/config_apollo_vocal.yaml'\n",
        "if model == 'Lew Universal Lossy Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_uni.ckpt'\n",
        "    config = 'configs/config_apollo_uni.yaml'\n",
        "\n",
        "!python inference.py \\\n",
        "    --in_wav '{input_file_path}' \\\n",
        "    --out_wav '{output_file_path}' \\\n",
        "    --chunk_size {chunk_size} \\\n",
        "    --overlap {overlap} \\\n",
        "    --ckpt '{ckpt}' \\\n",
        "    --config '{config}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "klhS37SXvwwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}